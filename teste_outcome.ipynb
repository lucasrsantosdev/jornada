{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt, timedelta\n",
    "from dotenv import load_dotenv # QUANDO NOS TIVERMOS O COFRE DE SEMHAS TROCAREMOS ESSA LIB PELA LIB DE CONSUMO DE CHAVES DA AWS\n",
    "from bs4 import BeautifulSoup\n",
    "from app_s3 import S3 # LIB AWS\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOME DO ARQUIVO\n",
    "nm_arq = 'outcome'\n",
    "\n",
    "# Credenciais de autenticação\n",
    "username = \"labutare-bi\"\n",
    "password = \"toYqCZweFTzX8AikcPAu4IspSxrsZtdN\"\n",
    "\n",
    "# Lista de endpoints\n",
    "url = \"https://api.sienge.com.br/labutare/public/api/bulk-data/v1/outcome\"\n",
    "\n",
    "# Parâmetros para endpoints que exigem filtros\n",
    "params = {\n",
    "    \"startDate\": \"2020-01-01\",\n",
    "    \"endDate\": format(dt.now(), '%Y-%m-%d'),\n",
    "    \"selectionType\": \"I\",\n",
    "    \"correctionIndexerId\": \"1\",\n",
    "    \"correctionDate\": format(dt.now(), '%Y-%m-%d'),\n",
    "    \"billsIds\": \"20\"\n",
    "}\n",
    "\n",
    "# Loop sobre os endpoints\n",
    "response = requests.get(url, auth=(username, password), params=params if \"bulk-data\" in url else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    data = response.json()['data']\n",
    "\n",
    "    df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_and_normalize(df, explode_columns):\n",
    "\n",
    "    df_result = df.copy()\n",
    "\n",
    "    for col in explode_columns:\n",
    "        df_exploded = df_result.explode(col)\n",
    "        df_final = pd.json_normalize(df_exploded[col])\n",
    "\n",
    "        l_colunas = [f'{col}_{u}' for u in list(df_final.columns)]\n",
    "        df_final.rename(columns=dict(zip(df_final.columns, l_colunas)), inplace=True)\n",
    "\n",
    "        df_result = pd.concat([df_exploded.reset_index(drop=True), df_final], axis=1).drop(columns=[col])\n",
    "\n",
    "    return df_result\n",
    "\n",
    "explode_columns = [\"paymentsCategories\", \"departamentsCosts\", \"buildingsCosts\", \"payments\", \"authorizations\",\n",
    "                   \"payments_bankMovements\",\"payments_bankMovements_paymentCategories\"]\n",
    "df_geral = explode_and_normalize(df, explode_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geral.to_csv(\"teste_outcome.csv\", sep=';', encoding='utf-8-sig', decimal=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
